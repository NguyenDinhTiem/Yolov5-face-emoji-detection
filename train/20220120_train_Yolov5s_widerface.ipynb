{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20220120_train_widerface.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oT2wunQT8kBu","executionInfo":{"status":"ok","timestamp":1636093970844,"user_tz":-420,"elapsed":62996,"user":{"displayName":"Nguyễn Đình Tiềm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09669651428312214322"}},"outputId":"8c2285d4-a3b4-4ab5-e176-f9fce6047ec6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYE5s9l_HtP1","executionInfo":{"status":"ok","timestamp":1633601181844,"user_tz":-420,"elapsed":15,"user":{"displayName":"Đình Tiềm Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg62lOfyzHgGBVSPluxxif3QwRmdew8VrjLauGn=s64","userId":"13269040847340645523"}},"outputId":"de5d91d7-c6c0-4f04-9d08-7ddd0a8dc645"},"source":["%cd /content/drive/MyDrive/Nhan_Dien_Cam_Xuc/Face"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1w-id1OmGr-aKHYWitHQgseaiaXNVVPZN/Nhan_Dien_Cam_Xuc/Face\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hbzu41SH_tu","executionInfo":{"status":"ok","timestamp":1631787713783,"user_tz":-420,"elapsed":6936,"user":{"displayName":"Nguyễn Đình Tiềm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09669651428312214322"}},"outputId":"29886420-9f84-4bfd-921a-1fe15f29c373"},"source":["!git clone https://github.com/ultralytics/yolov5.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 9339, done.\u001b[K\n","remote: Counting objects: 100% (1/1), done.\u001b[K\n","remote: Total 9339 (delta 0), reused 0 (delta 0), pack-reused 9338\u001b[K\n","Receiving objects: 100% (9339/9339), 9.75 MiB | 6.24 MiB/s, done.\n","Resolving deltas: 100% (6491/6491), done.\n","Checking out files: 100% (96/96), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yfcBpaSaIGg3","executionInfo":{"status":"ok","timestamp":1632332663289,"user_tz":-420,"elapsed":312,"user":{"displayName":"Nguyễn Đình Tiềm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09669651428312214322"}},"outputId":"97a1b686-4d31-4981-a791-dc75a8cfd3d4"},"source":["%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DjI1YRKsINPZ","executionInfo":{"status":"ok","timestamp":1632378260830,"user_tz":-420,"elapsed":65266,"user":{"displayName":"Đình Tiềm Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg62lOfyzHgGBVSPluxxif3QwRmdew8VrjLauGn=s64","userId":"13269040847340645523"}},"outputId":"57bc4d07-9a4e-4c41-afbc-696e32b156b8"},"source":["import shutil\n","\n","shutil.copy(\"/content/drive/MyDrive/Nhan_Dien_Cam_Xuc/yolov5/data/Data.zip\",\"/content\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/Data.zip'"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"1GLnF-RWJkoX"},"source":["!unzip '/content/Data.zip'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZVSgQJoJvsH","executionInfo":{"status":"ok","timestamp":1636093976486,"user_tz":-420,"elapsed":2184,"user":{"displayName":"Nguyễn Đình Tiềm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09669651428312214322"}},"outputId":"63767202-59e8-4e25-8358-c29df779eca1"},"source":["%cd /content/drive/MyDrive/Nhan_Dien_Cam_Xuc/Face/yolov5"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1w-id1OmGr-aKHYWitHQgseaiaXNVVPZN/Nhan_Dien_Cam_Xuc/Face/yolov5\n"]}]},{"cell_type":"code","metadata":{"id":"BQ_6OMUeJUUX"},"source":["pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_OZJT3FJ4xl","outputId":"024c30e9-93ea-40fe-bf47-cb899ddc5447"},"source":["!python train.py --img 640 --batch 64 --epochs 50 --data data/Data_face.yaml --weights yolov5s.pt "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data/Data_face.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=50, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 2021-9-16 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n","  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 283 layers, 7063542 parameters, 7063542 gradients, 16.4 GFLOPs\n","\n","Transferred 356/362 items from yolov5s.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Data/train/labels.cache' images and labels... 12880 found, 0 missing, 0 empty, 8 corrupted: 100% 12880/12880 [00:00<?, ?it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/0_Parade_Parade_0_452.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Political_Rally_2_444.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Protesters_2_231.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/37_Soccer_Soccer_37_851.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/39_Ice_Skating_iceskiing_39_380.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/46_Jockey_Jockey_46_576.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/58_Hockey_icehockey_puck_58_947.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/7_Cheering_Cheering_7_17.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Data/train/labels.cache' images and labels... 12880 found, 0 missing, 0 empty, 8 corrupted: 100% 12880/12880 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Data/val/labels.cache' images and labels... 3226 found, 0 missing, 0 empty, 6 corrupted: 100% 3226/3226 [00:00<?, ?it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/0_Parade_Parade_0_275.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/21_Festival_Festival_21_604.jpg: duplicate labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/37_Soccer_soccer_ball_37_281.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/50_Celebration_Or_Party_houseparty_50_715.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_171.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_426.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Data/val/labels.cache' images and labels... 3226 found, 0 missing, 0 empty, 6 corrupted: 100% 3226/3226 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.17, Best Possible Recall (BPR) = 0.9711. Attempting to improve anchors, please wait...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 6025 of 158334 labels are < 3 pixels in size.\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 157912 points...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9991 best possible recall, 4.60 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.328/0.814-mean/best, past_thr=0.537-mean: 4,5,  7,9,  12,15,  18,23,  27,34,  42,55,  69,92,  122,163,  222,290\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8210: 100% 1000/1000 [00:44<00:00, 22.62it/s]\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9991 best possible recall, 4.69 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.336/0.820-mean/best, past_thr=0.542-mean: 4,5,  7,8,  10,13,  15,19,  24,31,  41,54,  68,88,  106,141,  210,293\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n","\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp4\u001b[0m\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/49     11.4G    0.1043   0.05126         0       194       640: 100% 202/202 [17:24<00:00,  5.17s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:34<00:00,  3.63s/it]\n","                 all       3220      39339      0.392      0.347      0.264     0.0658\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/49     11.3G   0.07981   0.04869         0        45       640: 100% 202/202 [17:41<00:00,  5.26s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:30<00:00,  3.49s/it]\n","                 all       3220      39339      0.674      0.452      0.491      0.185\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/49     11.3G    0.0736    0.0485         0        71       640: 100% 202/202 [17:17<00:00,  5.14s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:31<00:00,  3.51s/it]\n","                 all       3220      39339      0.762      0.502      0.554      0.249\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/49     11.3G   0.06983   0.04906         0        94       640: 100% 202/202 [17:15<00:00,  5.13s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:30<00:00,  3.49s/it]\n","                 all       3220      39339       0.77      0.522      0.578      0.261\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/49     11.3G   0.06878   0.04816         0       130       640: 100% 202/202 [17:12<00:00,  5.11s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:31<00:00,  3.50s/it]\n","                 all       3220      39339      0.753      0.454      0.514      0.217\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/49     11.3G   0.06697   0.04893         0       139       640: 100% 202/202 [17:18<00:00,  5.14s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:33<00:00,  3.60s/it]\n","                 all       3220      39339      0.803      0.506      0.575      0.247\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      6/49     11.3G   0.06557   0.04806         0        45       640: 100% 202/202 [17:29<00:00,  5.19s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:31<00:00,  3.52s/it]\n","                 all       3220      39339      0.816      0.537      0.605      0.276\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      7/49     11.3G   0.06516   0.04746         0       241       640: 100% 202/202 [17:22<00:00,  5.16s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:31<00:00,  3.51s/it]\n","                 all       3220      39339      0.796      0.512      0.579       0.27\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      8/49     11.3G   0.06364   0.04742         0        63       640: 100% 202/202 [17:27<00:00,  5.19s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:33<00:00,  3.58s/it]\n","                 all       3220      39339      0.822      0.544       0.61      0.297\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      9/49     11.3G   0.06348   0.04736         0       132       640: 100% 202/202 [17:31<00:00,  5.21s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:33<00:00,  3.58s/it]\n","                 all       3220      39339      0.846      0.571      0.643      0.311\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     10/49     11.3G   0.06355    0.0467         0      1021       640:  93% 187/202 [16:23<01:17,  5.16s/it]"]}]},{"cell_type":"code","metadata":{"id":"wuxIvORA70c6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"397d98ea-8567-4486-efb7-b8ccdce53689"},"source":["!python train.py --img 640 --batch 64 --epochs 50 --data data/Data_face.yaml --weights runs/train/exp4/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 18.9MB/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp4/weights/last.pt, cfg=, data=data/Data_face.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=50, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n","remote: Enumerating objects: 18, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 18 (delta 6), reused 12 (delta 5), pack-reused 0\u001b[K\n","\u001b[34m\u001b[1mgithub: \u001b[0mCommand 'git fetch && git config --get remote.origin.url' timed out after 5 seconds\n","Unpacking objects: 100% (18/18), done.\n","YOLOv5 🚀 2021-9-16 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","From https://github.com/ultralytics/yolov5\n","   0dc725e..27a4736  master     -> origin/master\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n","  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 283 layers, 7063542 parameters, 7063542 gradients, 16.4 GFLOPs\n","\n","Transferred 362/362 items from runs/train/exp4/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Data/train/labels' images and labels...12880 found, 0 missing, 0 empty, 8 corrupted: 100% 12880/12880 [00:08<00:00, 1595.71it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/0_Parade_Parade_0_452.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Political_Rally_2_444.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Protesters_2_231.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/37_Soccer_Soccer_37_851.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/39_Ice_Skating_iceskiing_39_380.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/46_Jockey_Jockey_46_576.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/58_Hockey_icehockey_puck_58_947.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/7_Cheering_Cheering_7_17.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Data/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Data/val/labels' images and labels...3226 found, 0 missing, 0 empty, 6 corrupted: 100% 3226/3226 [00:03<00:00, 891.40it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/0_Parade_Parade_0_275.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/21_Festival_Festival_21_604.jpg: duplicate labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/37_Soccer_soccer_ball_37_281.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/50_Celebration_Or_Party_houseparty_50_715.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_171.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_426.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Data/val/labels.cache\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.71, Best Possible Recall (BPR) = 0.9996\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp5\u001b[0m\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     10/49     11.3G   0.06311   0.04666         0       209       640: 100% 202/202 [17:00<00:00,  5.05s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:28<00:00,  3.40s/it]\n","                 all       3220      39339      0.825      0.537      0.609      0.286\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     11/49     11.4G   0.06328   0.04657         0        63       640: 100% 202/202 [16:50<00:00,  5.00s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:27<00:00,  3.37s/it]\n","                 all       3220      39339      0.836      0.566      0.637      0.297\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     12/49     11.4G   0.06256   0.04584         0        64       640: 100% 202/202 [16:48<00:00,  4.99s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:29<00:00,  3.43s/it]\n","                 all       3220      39339      0.815      0.531      0.592      0.279\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     13/49     11.4G   0.06207   0.04687         0       110       640: 100% 202/202 [16:52<00:00,  5.01s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:30<00:00,  3.50s/it]\n","                 all       3220      39339      0.833      0.566      0.632      0.303\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     14/49     11.4G   0.06196   0.04558         0       197       640: 100% 202/202 [17:23<00:00,  5.17s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:41<00:00,  3.91s/it]\n","                 all       3220      39339      0.846      0.578      0.647       0.31\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     15/49     11.4G   0.06216   0.04823         0       887       640:  68% 137/202 [12:50<06:24,  5.92s/it]"]}]},{"cell_type":"code","metadata":{"id":"KiqUwhP5J40K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"01ec4387-3f29-4009-f0d0-a0dc20316f3e"},"source":["!python train.py --img 640 --batch 64 --epochs 50 --data data/Data_face.yaml --weights runs/train/exp5/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp5/weights/last.pt, cfg=, data=data/Data_face.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=50, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n","\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n","YOLOv5 🚀 v5.0-434-g0dc725e torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n","  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 283 layers, 7063542 parameters, 7063542 gradients, 16.4 GFLOPs\n","\n","Transferred 362/362 items from runs/train/exp5/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Data/train/labels' images and labels...12880 found, 0 missing, 0 empty, 8 corrupted: 100% 12880/12880 [00:08<00:00, 1488.12it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/0_Parade_Parade_0_452.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Political_Rally_2_444.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Protesters_2_231.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/37_Soccer_Soccer_37_851.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/39_Ice_Skating_iceskiing_39_380.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/46_Jockey_Jockey_46_576.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/58_Hockey_icehockey_puck_58_947.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/7_Cheering_Cheering_7_17.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Data/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Data/val/labels' images and labels...3226 found, 0 missing, 0 empty, 6 corrupted: 100% 3226/3226 [00:03<00:00, 869.14it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/0_Parade_Parade_0_275.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/21_Festival_Festival_21_604.jpg: duplicate labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/37_Soccer_soccer_ball_37_281.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/50_Celebration_Or_Party_houseparty_50_715.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_171.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_426.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Data/val/labels.cache\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.71, Best Possible Recall (BPR) = 0.9992\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp7\u001b[0m\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     15/49     11.3G   0.06188   0.04644         0       104       640: 100% 202/202 [18:15<00:00,  5.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:38<00:00,  3.79s/it]\n","                 all       3220      39339      0.837      0.559      0.629      0.308\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     16/49     11.4G   0.06114   0.04479         0        64       640: 100% 202/202 [18:21<00:00,  5.45s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:37<00:00,  3.76s/it]\n","                 all       3220      39339      0.846      0.577      0.648       0.31\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     17/49     11.4G   0.06142   0.04594         0       161       640: 100% 202/202 [18:17<00:00,  5.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:36<00:00,  3.71s/it]\n","                 all       3220      39339      0.827      0.579       0.64      0.312\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     18/49     11.4G    0.0607   0.04528         0        67       640: 100% 202/202 [18:24<00:00,  5.47s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:37<00:00,  3.77s/it]\n","                 all       3220      39339      0.839      0.584      0.652      0.304\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     19/49     11.4G   0.06088   0.04495         0       159       640: 100% 202/202 [18:20<00:00,  5.45s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:36<00:00,  3.72s/it]\n","                 all       3220      39339      0.844      0.578      0.646      0.318\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     20/49     11.4G   0.06083   0.04533         0       119       640: 100% 202/202 [18:13<00:00,  5.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:34<00:00,  3.65s/it]\n","                 all       3220      39339       0.83      0.576      0.646      0.309\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     21/49     11.4G   0.06009   0.04493         0        50       640: 100% 202/202 [18:12<00:00,  5.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:35<00:00,  3.66s/it]\n","                 all       3220      39339      0.841      0.583      0.651      0.318\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     22/49     11.4G   0.05982    0.0446         0       226       640: 100% 202/202 [18:03<00:00,  5.36s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:32<00:00,  3.55s/it]\n","                 all       3220      39339      0.844      0.584      0.654      0.319\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     23/49     11.4G   0.05941   0.04496         0        75       640: 100% 202/202 [17:55<00:00,  5.33s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:37<00:00,  3.75s/it]\n","                 all       3220      39339      0.838      0.585      0.654      0.319\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     24/49     11.4G   0.06008    0.0445         0       143       640: 100% 202/202 [18:53<00:00,  5.61s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:40<00:00,  3.87s/it]\n","                 all       3220      39339      0.845      0.591      0.661      0.321\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     25/49     11.4G   0.06005    0.0446         0        67       640: 100% 202/202 [18:13<00:00,  5.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:34<00:00,  3.63s/it]\n","                 all       3220      39339      0.856      0.605      0.673      0.342\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     26/49     11.4G   0.05949   0.04472         0        62       640: 100% 202/202 [17:53<00:00,  5.31s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:36<00:00,  3.70s/it]\n","                 all       3220      39339      0.833      0.605      0.667      0.328\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     27/49     11.4G   0.06017   0.04517         0       173       640: 100% 202/202 [17:47<00:00,  5.28s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:37<00:00,  3.74s/it]\n","                 all       3220      39339      0.853      0.591      0.664      0.329\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     28/49     11.4G   0.05993   0.04494         0        48       640: 100% 202/202 [18:20<00:00,  5.45s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:36<00:00,  3.70s/it]\n","                 all       3220      39339      0.849       0.59      0.662       0.32\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     29/49     11.4G   0.05966    0.0446         0       194       640: 100% 202/202 [18:17<00:00,  5.44s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:37<00:00,  3.75s/it]\n","                 all       3220      39339      0.847      0.601       0.67      0.332\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     30/49     11.4G   0.05902   0.04436         0       107       640: 100% 202/202 [18:09<00:00,  5.39s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:35<00:00,  3.68s/it]\n","                 all       3220      39339      0.841      0.585      0.654       0.32\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     31/49     11.4G   0.05864   0.04386         0        43       640: 100% 202/202 [18:13<00:00,  5.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:36<00:00,  3.71s/it]\n","                 all       3220      39339      0.844      0.601       0.67      0.326\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     32/49     11.4G   0.05868   0.04417         0        37       640: 100% 202/202 [18:17<00:00,  5.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:36<00:00,  3.72s/it]\n","                 all       3220      39339      0.835      0.609      0.672      0.333\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     33/49     11.4G   0.05876   0.04382         0        62       640: 100% 202/202 [18:22<00:00,  5.46s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:38<00:00,  3.79s/it]\n","                 all       3220      39339       0.85      0.595      0.667      0.331\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     34/49     11.4G    0.0594   0.04855         0      1330       640:  43% 87/202 [07:50<09:53,  5.16s/it]"]}]},{"cell_type":"code","metadata":{"id":"Mb3bzzwwJ423","colab":{"base_uri":"https://localhost:8080/"},"outputId":"77523486-a306-4fe4-f79f-208e96a8beff"},"source":["!python train.py --img 640 --batch 64 --epochs 50 --data data/Data_face.yaml --weights runs/train/exp7/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp7/weights/last.pt, cfg=, data=data/Data_face.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=50, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n","remote: Enumerating objects: 119, done.\u001b[K\n","remote: Counting objects: 100% (59/59), done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 119 (delta 52), reused 54 (delta 52), pack-reused 60\u001b[K\n","Receiving objects: 100% (119/119), 59.42 KiB | 3.71 MiB/s, done.\n","Resolving deltas: 100% (82/82), completed with 22 local objects.\n","\u001b[34m\u001b[1mgithub: \u001b[0mCommand 'git fetch && git config --get remote.origin.url' timed out after 5 seconds\n","YOLOv5 🚀 2021-9-16 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","From https://github.com/ultralytics/yolov5\n","   4d1a2ac..59aae85  master             -> origin/master\n"," * [new branch]      docker/20_08       -> origin/docker/20_08\n","   9d300aa..cda6ffd  exp/albumentations -> origin/exp/albumentations\n"," * [new branch]      tests/v6.0         -> origin/tests/v6.0\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n","  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 283 layers, 7063542 parameters, 7063542 gradients, 16.4 GFLOPs\n","\n","Transferred 362/362 items from runs/train/exp7/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Data/train/labels' images and labels...12880 found, 0 missing, 0 empty, 8 corrupted: 100% 12880/12880 [00:08<00:00, 1571.70it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/0_Parade_Parade_0_452.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Political_Rally_2_444.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Protesters_2_231.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/37_Soccer_Soccer_37_851.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/39_Ice_Skating_iceskiing_39_380.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/46_Jockey_Jockey_46_576.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/58_Hockey_icehockey_puck_58_947.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/7_Cheering_Cheering_7_17.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Data/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Data/val/labels' images and labels...3226 found, 0 missing, 0 empty, 6 corrupted: 100% 3226/3226 [00:03<00:00, 878.03it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/0_Parade_Parade_0_275.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/21_Festival_Festival_21_604.jpg: duplicate labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/37_Soccer_soccer_ball_37_281.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/50_Celebration_Or_Party_houseparty_50_715.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_171.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_426.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Data/val/labels.cache\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.71, Best Possible Recall (BPR) = 0.9995\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp20\u001b[0m\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     34/49     11.3G   0.05867   0.04383         0       105       640: 100% 202/202 [18:31<00:00,  5.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:40<00:00,  3.87s/it]\n","                 all       3220      39339      0.849      0.596      0.669      0.332\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     35/49     11.4G   0.05798   0.04307         0        66       640: 100% 202/202 [17:41<00:00,  5.25s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:28<00:00,  3.40s/it]\n","                 all       3220      39339      0.865      0.616      0.689      0.344\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     36/49     11.4G   0.06008   0.05384         0      1803       640:   8% 17/202 [01:18<15:36,  5.06s/it]"]}]},{"cell_type":"code","metadata":{"id":"15h1QeijJ45e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632384526732,"user_tz":-420,"elapsed":6043951,"user":{"displayName":"Đình Tiềm Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg62lOfyzHgGBVSPluxxif3QwRmdew8VrjLauGn=s64","userId":"13269040847340645523"}},"outputId":"beb35daa-8c35-43de-9ec7-341f9c82f750"},"source":["!python train.py --img 640 --batch 64 --epochs 50 --data data/Data_face.yaml --weights runs/train/exp20/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 16.1MB/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp20/weights/last.pt, cfg=, data=data/Data_face.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=50, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n","\u001b[34m\u001b[1mgithub: \u001b[0mCommand 'git fetch && git config --get remote.origin.url' timed out after 5 seconds\n","YOLOv5 🚀 v5.0-434-g0dc725e torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (3/3), done.\n","From https://github.com/ultralytics/yolov5\n"," * [new branch]      update/val_plots_on_best.pt -> origin/update/val_plots_on_best.pt\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n","  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 283 layers, 7063542 parameters, 7063542 gradients, 16.4 GFLOPs\n","\n","Transferred 362/362 items from runs/train/exp20/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Data/train/labels' images and labels...12880 found, 0 missing, 0 empty, 8 corrupted: 100% 12880/12880 [00:07<00:00, 1677.56it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/0_Parade_Parade_0_452.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Political_Rally_2_444.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/2_Demonstration_Protesters_2_231.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/37_Soccer_Soccer_37_851.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/39_Ice_Skating_iceskiing_39_380.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/46_Jockey_Jockey_46_576.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/58_Hockey_icehockey_puck_58_947.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/train/images/7_Cheering_Cheering_7_17.jpg: duplicate labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Data/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Data/val/labels' images and labels...3226 found, 0 missing, 0 empty, 6 corrupted: 100% 3226/3226 [00:03<00:00, 894.80it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/0_Parade_Parade_0_275.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/21_Festival_Festival_21_604.jpg: duplicate labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/37_Soccer_soccer_ball_37_281.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/50_Celebration_Or_Party_houseparty_50_715.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_171.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/Data/val/images/7_Cheering_Cheering_7_426.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Data/val/labels.cache\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.71, Best Possible Recall (BPR) = 0.9994\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp21\u001b[0m\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     45/49     11.3G   0.05738    0.0435         0       227       640: 100% 202/202 [18:02<00:00,  5.36s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:35<00:00,  3.68s/it]\n","                 all       3220      39339      0.864      0.599      0.678      0.338\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     46/49     11.4G   0.05659   0.04163         0        57       640: 100% 202/202 [18:10<00:00,  5.40s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:35<00:00,  3.69s/it]\n","                 all       3220      39339      0.862      0.609      0.685      0.342\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     47/49     11.4G   0.05677   0.04173         0        67       640: 100% 202/202 [18:10<00:00,  5.40s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:37<00:00,  3.74s/it]\n","                 all       3220      39339      0.859      0.601      0.678      0.338\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     48/49     11.4G   0.05658    0.0423         0        66       640: 100% 202/202 [17:59<00:00,  5.34s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:35<00:00,  3.67s/it]\n","                 all       3220      39339      0.845      0.611       0.68      0.338\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     49/49     11.4G   0.05714   0.04177         0       118       640: 100% 202/202 [17:52<00:00,  5.31s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [01:55<00:00,  4.45s/it]\n","                 all       3220      39339      0.849      0.613      0.683      0.341\n","\n","5 epochs completed in 1.647 hours.\n","Optimizer stripped from runs/train/exp21/weights/last.pt, 14.4MB\n","Results saved to \u001b[1mruns/train/exp21\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyWGwDq15Rah","executionInfo":{"status":"ok","timestamp":1636095466073,"user_tz":-420,"elapsed":6703,"user":{"displayName":"Nguyễn Đình Tiềm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09669651428312214322"}},"outputId":"b0c4a932-c1cc-4100-dd73-5d61d4355db3"},"source":["!python detect.py --img 640 --conf 0.45 --weights runs/train/exp21/weights/last.pt --source /content/drive/MyDrive/Nhan_Dien_Cam_Xuc/Face/yolov5/videos_test/h2.jpg --hide-labels --hide-conf"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp21/weights/last.pt'], source=/content/drive/MyDrive/Nhan_Dien_Cam_Xuc/Face/yolov5/videos_test/h2.jpg, imgsz=[640, 640], conf_thres=0.45, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=True, hide_conf=True, half=False\n","YOLOv5 🚀 v5.0-434-g0dc725e torch 1.9.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n","\n","Fusing layers... \n","Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPs\n","image 1/1 /content/drive/.shortcut-targets-by-id/1w-id1OmGr-aKHYWitHQgseaiaXNVVPZN/Nhan_Dien_Cam_Xuc/Face/yolov5/videos_test/h2.jpg: 480x640 156 faces, Done. (0.012s)\n","Speed: 0.5ms pre-process, 11.8ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp28\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"KX25qBGe5RdJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHk97Tu75RjN"},"source":[""],"execution_count":null,"outputs":[]}]}